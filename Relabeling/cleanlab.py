# Data processing and array-related libraries
import os
import random
import numpy as np
import pandas as pd

# PyTorch and Hugging Face related libraries
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Machine learning and vectorization tools with Scikit-learn
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# LightGBM library
import lightgbm as lgb

# Cleanlab library
from cleanlab.classification import CleanLearning

# Argument parsing
import argparse


SEED = 456
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')


def get_embedding_or_tokenize(texts, model_name) :
    '''
        Generates embeddings for the input text data using a specified model.

        Parameters:
        - texts (List[str]): A list of text data for which to generate embeddings.
        - model_name (str): The name of the model to use for embedding generation. 
                            Options include "TF-IDF" or the name of a pretrained model from Hugging Face.
        
        Returns:
        - scipy.sparse.csr_matrix: Returns embeddings as a sparse matrix when using TF-IDF.
        - List[dict]: For other models, returns a list of tokenized outputs, where each item is a dictionary 
                    containing 'input_ids' and 'attention_mask' keys for each text input.
    '''

    if model_name == "TF-IDF" :
        vectorizer = TfidfVectorizer()
        embeddings = vectorizer.fit_transform(texts)
    else :
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        embeddings = []
        for text in texts :
            inputs = tokenizer(text, return_tensors='pt')
            embeddings.append(text)
    
    return embeddings


def get_pred_probs(embeddings, labels, model_name, saved_model_path = None) :
    '''
        Generates prediction probabilities for input embeddings using a specified model.

        Parameters:
        - embeddings (scipy.sparse.csr_matrix or List[dict]): Text embeddings for calculating prediction probabilities.
            - When using the "Logistic" model: Embeddings in the form of a sparse matrix generated by TF-IDF.
            - For other models: A list of tokenized inputs, each containing 'input_ids' and 'attention_mask' keys.
            
        - labels (List[int]): A list of actual labels associated with the embeddings.

        - model_name (str): The name of the model to use for prediction.
            - If set to "Logistic," uses a Logistic Regression model to calculate prediction probabilities.
            - Any other name is considered a pretrained classification model from Hugging Face.
        
        - saved_model_path (str, optional): Path to the pretrained classification model.
            - If specified, loads the model from this path; if not, loads the model from the Hugging Face model hub using `model_name`.

        Returns:
        - pred_probs (numpy.ndarray): An array of prediction probabilities with shape `(num_text, num_label)`.
            - Indicates the probability of each text belonging to each label.
            - Returns in a consistent format usable for both "Logistic" and Hugging Face models.
    '''
    if model_name == "Logistic" :
        model = LogisticRegression()
        model.fit(embeddings, labels)
        pred_probs = model.predict_proba(embeddings) # (num_text, num_label)
    else :
        if saved_model_path is not None :
            model = AutoModelForSequenceClassification.from_pretrained(saved_model_path).to(DEVICE)
        else :
            model = AutoModelForSequenceClassification.from_pretrained(model_name).to(DEVICE)
        
        model.eval()
        logits = []
        for embedding in embeddings :
            with torch.no_grad() :
                input = embedding.to(DEVICE)
                logits.append(model(**input).logits)
        logits = torch.concat(logits, dim = 0) # (num_text, num_label)

        pred_probs = torch.softmax(logits, dim = 1).cpu().numpy() # (num_text, num_label)

    return pred_probs



def main() :
    parser = argparse.ArgumentParser()
    parser.add_argument("--embedding_model_type", type=str,
                        help="Type of model to use for generating embeddings.")
    parser.add_argument("--predict_model_type", type=str,
                        help="Type of model to use for generating prediction probabilities.")
    parser.add_argument("--saved_model_path", str, default=None,
                        help="Path to a saved model for generating prediction probabilities. If not provided, uses `predict_model_type`.")
    parser.add_argument("--clf_type", type=str, 
                        help="Type of classifier to use with Cleanlab for label correction. Options: 'Logistic', 'RandomForest', 'LGBM'.")
    parser.add_argument("--data_path", type=str,
                        help="Path to the input data CSV file containing `text` and `target` columns.")
    parser.add_argument("--output_dir", type=str,
                        help="Directory to save the output files, including label quality evaluation and corrected labels.")
    
    args = parser.parse_args()

    os.mkdir(args.output_dir, exist_ok =True)
    
    origin_data = pd.read_csv(args.data_path)
    texts = origin_data['text'].values
    labels = origin_data['target'].values
    
    embeddings = get_embedding_or_tokenize(texts, args.embedding_model_type)
    pred_probs = get_pred_probs(embeddings, labels, 
                                args.predict_model_type,args.saved_model_path)

    if args.clf_type == "Logistic" :
        clf = LogisticRegression()
    elif args.clf_type == "RandomForest" :
        clf = RandomForestClassifier()
    elif args.clf_type == "LGBM" :
        clf = lgb.LGBMClassifier(n_estimators=100, random_state=SEED)
    else :
        raise ValueError(f"{args.clf_type} clf type is not implemented. Use a different clf type.")
    clean_learning = CleanLearning(clf)

    ## Evaluate label quality 
    label_quality_path = os.path.join(args.output_dir, "label_quality.csv")
    label_issues = clean_learning.find_label_issues(labels = labels, pred_probs = pred_probs)
    # Calculate label quality based on a given probability
    label_issues.to_csv(label_quality_path)
    print(f"Data about the quality of the labels was saved in {label_quality_path}.")

    ## Correcting invalid labels.
    corrected_labels_path = os.path.join(args.output_dir, "label-corrected.csv")
    _ = CleanLearning.fit(pred_probs, labels)
    corrected_labels = clean_learning.predict(pred_probs)
    # CLF modifies labels based on a given probability
    origin_data['corrected_target'] = corrected_labels
    origin_data.to_csv(corrected_labels_path)
    print(f"The label-corrected data was saved in {corrected_labels_path}.")

    num_corrected_labels = (corrected_labels != labels).sum()
    print(f"{num_corrected_labels} labels out of {len(labels)} were corrected.")


if __name__ == "__main__":
    main()