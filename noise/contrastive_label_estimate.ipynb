{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ-n74gNGJ0n"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ieJqZz6WGJ0n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# wandb 프로젝트 설정\n",
    "\n",
    "# os.environ[\"WANDB_API_KEY\"]=\"6ee5e8ab1b91bbcf8be3098caaec592b8a6682c4\"\n",
    "# os.environ[\"WANDB_PROJECT\"] = \"level2_data-centric-contrastive-relabeling\"\n",
    "\n",
    "# # # wandb 초기화\n",
    "# # # wandb.finish()\n",
    "\n",
    "# wandb.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9MrGeVLGJ0o"
   },
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rojb26TRGJ0o"
   },
   "outputs": [],
   "source": [
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHiKw7tAGJ0o",
    "outputId": "fa675ab9-3221-4ef1-dabb-42e2aad2192c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ANUH4JCxGJ0o"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, '../data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'outputs')\n",
    "\n",
    "# labeled_data_path = os.path.join(DATA_DIR, \"cleaning_step1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuP9IW9mGJ0o"
   },
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HH0lhDvhGJ0o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'klue/bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2NvoGbGJ0o"
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gE13nELlGJ0o"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_DIR+f\"/recovery_data/converted_train_ver2_fewshot.csv\")\n",
    "train_df = df[df['is_noisy'] == 1]\n",
    "dataset_train, dataset_valid = train_test_split(train_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>ascii_ratio</th>\n",
       "      <th>is_noisy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>ynat-v1_train_00766</td>\n",
       "      <td>T타임즈, 최고의 음식 애호가들을 위한 스마트폰 앱</td>\n",
       "      <td>4</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>ynat-v1_train_01010</td>\n",
       "      <td>노키리아·피씨손민…겨울은 베트남 연휴</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>ynat-v1_train_00950</td>\n",
       "      <td>부처님 상원 공식 표창 받</td>\n",
       "      <td>6</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>ynat-v1_train_00592</td>\n",
       "      <td>에어프라이어 업력 높아져 이지로 바꿔 연결</td>\n",
       "      <td>4</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>ynat-v1_train_02676</td>\n",
       "      <td>클래식 공연 즐겨 낮도 자…영화의 변신</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>ynat-v1_train_01573</td>\n",
       "      <td>여경투톱 체제 반 평…민주적재 한국 우선</td>\n",
       "      <td>2</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>ynat-v1_train_00846</td>\n",
       "      <td>슬기로운 해양 경에 난민 대응 군 배치</td>\n",
       "      <td>6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ynat-v1_train_00065</td>\n",
       "      <td>북 리수이 국제사회 임시 일원 되는데 기대감</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>ynat-v1_train_01016</td>\n",
       "      <td>오바마 폭스마켓 사^^ 대규모 감^^...누적 ^자^^^</td>\n",
       "      <td>6</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>ynat-v1_train_01033</td>\n",
       "      <td>삼성 갤럭시 폴드 Z 폴더형 스마트폰 출시</td>\n",
       "      <td>4</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                             text  target  \\\n",
       "766   ynat-v1_train_00766     T타임즈, 최고의 음식 애호가들을 위한 스마트폰 앱       4   \n",
       "1010  ynat-v1_train_01010             노키리아·피씨손민…겨울은 베트남 연휴       0   \n",
       "950   ynat-v1_train_00950                   부처님 상원 공식 표창 받       6   \n",
       "592   ynat-v1_train_00592          에어프라이어 업력 높아져 이지로 바꿔 연결       4   \n",
       "2676  ynat-v1_train_02676            클래식 공연 즐겨 낮도 자…영화의 변신       0   \n",
       "...                   ...                              ...     ...   \n",
       "1573  ynat-v1_train_01573           여경투톱 체제 반 평…민주적재 한국 우선       2   \n",
       "846   ynat-v1_train_00846            슬기로운 해양 경에 난민 대응 군 배치       6   \n",
       "65    ynat-v1_train_00065         북 리수이 국제사회 임시 일원 되는데 기대감       2   \n",
       "1016  ynat-v1_train_01016  오바마 폭스마켓 사^^ 대규모 감^^...누적 ^자^^^       6   \n",
       "1033  ynat-v1_train_01033          삼성 갤럭시 폴드 Z 폴더형 스마트폰 출시       4   \n",
       "\n",
       "      ascii_ratio  is_noisy  \n",
       "766      0.451613         1  \n",
       "1010     0.566667         1  \n",
       "950      0.562500         1  \n",
       "592      0.560000         1  \n",
       "2676     0.240000         1  \n",
       "...           ...       ...  \n",
       "1573     0.387097         1  \n",
       "846      0.428571         1  \n",
       "65       0.500000         1  \n",
       "1016     0.583333         1  \n",
       "1033     0.321429         1  \n",
       "\n",
       "[1296 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>ascii_ratio</th>\n",
       "      <th>is_noisy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>ynat-v1_train_02001</td>\n",
       "      <td>노동자 한낮 초록 더 미세·오존 위험</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>ynat-v1_train_01098</td>\n",
       "      <td>주택금융^^카^^뱅크 택금융 개발 협력</td>\n",
       "      <td>5</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>ynat-v1_train_02046</td>\n",
       "      <td>책을 쓸 때 비어 있는 페이지는 ^맞아요</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ynat-v1_train_00958</td>\n",
       "      <td>러시아 정식 제안 온면 푸틴 만나게 될 것</td>\n",
       "      <td>6</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>ynat-v1_train_00329</td>\n",
       "      <td>김정은 평양 제2래과학자거리 착공 지시</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ynat-v1_train_00231</td>\n",
       "      <td>드라마 쉽게 열리지 않는 멕시코 골목</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>ynat-v1_train_00646</td>\n",
       "      <td>삼성전자 설계전문가</td>\n",
       "      <td>4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>ynat-v1_train_00475</td>\n",
       "      <td>콘텐츠 왜 나한텐 페이스북은 유명하지</td>\n",
       "      <td>4</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>ynat-v1_train_00527</td>\n",
       "      <td>롯데건설·폐수 슬러지 건조기술 환경에서 녹색인증</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>ynat-v1_train_01761</td>\n",
       "      <td>美 수출 전제재 날이 가까워져 소문 흉작</td>\n",
       "      <td>6</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                        text  target  ascii_ratio  \\\n",
       "2001  ynat-v1_train_02001        노동자 한낮 초록 더 미세·오존 위험       0     0.458333   \n",
       "1098  ynat-v1_train_01098       주택금융^^카^^뱅크 택금융 개발 협력       5     0.375000   \n",
       "2046  ynat-v1_train_02046      책을 쓸 때 비어 있는 페이지는 ^맞아요       0     0.483871   \n",
       "958   ynat-v1_train_00958     러시아 정식 제안 온면 푸틴 만나게 될 것       6     0.392857   \n",
       "329   ynat-v1_train_00329       김정은 평양 제2래과학자거리 착공 지시       2     0.307692   \n",
       "...                   ...                         ...     ...          ...   \n",
       "231   ynat-v1_train_00231        드라마 쉽게 열리지 않는 멕시코 골목       1     0.400000   \n",
       "646   ynat-v1_train_00646                  삼성전자 설계전문가       4     0.454545   \n",
       "475   ynat-v1_train_00475        콘텐츠 왜 나한텐 페이스북은 유명하지       4     0.321429   \n",
       "527   ynat-v1_train_00527  롯데건설·폐수 슬러지 건조기술 환경에서 녹색인증       5     0.250000   \n",
       "1761  ynat-v1_train_01761      美 수출 전제재 날이 가까워져 소문 흉작       6     0.451613   \n",
       "\n",
       "      is_noisy  \n",
       "2001         1  \n",
       "1098         1  \n",
       "2046         1  \n",
       "958          1  \n",
       "329          1  \n",
       "...        ...  \n",
       "231          1  \n",
       "646          1  \n",
       "475          1  \n",
       "527          1  \n",
       "1761         1  \n",
       "\n",
       "[324 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 196, 1: 188, 0: 186, 4: 185, 5: 182, 2: 181, 6: 178}\n",
      "{4: 56, 6: 50, 0: 45, 1: 45, 2: 45, 5: 44, 3: 39}\n"
     ]
    }
   ],
   "source": [
    "train_counts = dataset_train['target'].value_counts().to_dict()\n",
    "valid_counts = dataset_valid['target'].value_counts().to_dict()\n",
    "\n",
    "# 결과 출력\n",
    "print(train_counts)\n",
    "print(valid_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9BQVS286GJ0o"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        input_texts = data['text']\n",
    "        targets = data['target']\n",
    "        self.inputs = []; self.labels = []\n",
    "        for text, label in zip(input_texts, targets):\n",
    "            tokenized_input = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'].squeeze(0),\n",
    "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx].squeeze(0)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BVycj2wPGJ0p"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, tokenizer)\n",
    "data_valid = BERTDataset(dataset_valid, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5yh5dYa0GJ0p"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766     4\n",
       "1010    0\n",
       "950     6\n",
       "592     4\n",
       "2676    0\n",
       "       ..\n",
       "1573    2\n",
       "846     6\n",
       "65      2\n",
       "1016    6\n",
       "1033    4\n",
       "Name: target, Length: 1296, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 대조 손실 함수 정의\n",
    "# def contrastive_loss(embeddings, labels, margin=1.0):\n",
    "#     distance_matrix = torch.cdist(embeddings, embeddings, p=2)  # 샘플 간 거리 계산\n",
    "#     positive_pairs = (labels.unsqueeze(1) == labels.unsqueeze(0)).float()  # 긍정적 쌍\n",
    "#     negative_pairs = 1 - positive_pairs  # 부정적 쌍\n",
    "\n",
    "#     loss = (positive_pairs * (distance_matrix ** 2)).sum() + \\\n",
    "#            (negative_pairs * F.relu(margin - distance_matrix)).sum()\n",
    "\n",
    "#     return loss / (embeddings.shape[0] ** 2)  # 평균 손실 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대조 손실 함수 정의\n",
    "def contrastive_loss(embeddings, labels, margin=1.0):\n",
    "    distance_matrix = torch.cdist(embeddings, embeddings, p=2)  # 샘플 간 거리 계산\n",
    "    positive_pairs = (labels.unsqueeze(1) == labels.unsqueeze(0)).float()  # 긍정적 쌍\n",
    "    negative_pairs = 1 - positive_pairs  # 부정적 쌍\n",
    "\n",
    "    # 손실 계산\n",
    "    pos_loss = (positive_pairs * (distance_matrix ** 2)).sum()  # 긍정적 손실\n",
    "    neg_loss = (negative_pairs * F.relu(margin - distance_matrix)).sum()  # 부정적 손실\n",
    "\n",
    "    # 긍정적 쌍과 부정적 쌍의 수\n",
    "    num_positive_pairs = positive_pairs.sum() + 1e-6  # 0으로 나누는 것을 방지\n",
    "    num_negative_pairs = negative_pairs.sum() + 1e-6\n",
    "\n",
    "    # 평균 손실 계산\n",
    "    total_loss = (pos_loss / num_positive_pairs) + (neg_loss / num_negative_pairs)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_contrastive_loss(embeddings, labels, margin=1.0):\n",
    "    # 거리 계산\n",
    "    distance_matrix = torch.cdist(embeddings, embeddings, p=2)\n",
    "    \n",
    "    # 각 클래스의 긍정적 쌍과 부정적 쌍을 계산\n",
    "    pos_loss = 0.0\n",
    "    neg_loss = 0.0\n",
    "    num_classes = 7\n",
    "    for class_id in range(num_classes):  # num_classes는 전체 클래스 수\n",
    "        # 긍정적 쌍: 현재 클래스의 임베딩\n",
    "        pos_mask = (labels.unsqueeze(1) == class_id) & (labels.unsqueeze(0) == class_id)\n",
    "        pos_pairs = distance_matrix[pos_mask]\n",
    "        # print(\"class_id = \",class_id,\"pos_pairs\", pos_pairs)\n",
    "        pos_loss += pos_pairs.sum()  # 긍정적 쌍에 대한 손실\n",
    "\n",
    "        # 부정적 쌍: 현재 클래스의 임베딩이 아닌 것\n",
    "        neg_mask = (labels.unsqueeze(1) == class_id) & (labels.unsqueeze(0) != class_id)\n",
    "        neg_pairs = distance_matrix[neg_mask]\n",
    "        neg_loss += F.relu(margin - neg_pairs).sum()  # 부정적 쌍에 대한 손실\n",
    "\n",
    "    # 평균 손실 계산\n",
    "    total_loss = (pos_loss / (pos_mask.1esum() + -6)) + (neg_loss / (neg_mask.sum() + 1e-6))\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # 입력을 모델에 통과시키고 임베딩을 추출\n",
    "        # outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], output_hidden_states=True)\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        logits = outputs.logits\n",
    "        # embeddings = outputs.hidden_states[-1][:, 1:, :].mean(dim=1)  # [CLS]를 제외한 평균 임베딩\n",
    "        # embeddings = outputs.hidden_states[-1].mean(dim=1)\n",
    "        embeddings = outputs.hidden_states[-1][:, 0, :]  # [CLS] 임베딩\n",
    "        # print(\"compute_loss(inputs) :::: \", inputs)\n",
    "        print(\"compute_loss(embeddings) ::::\", embeddings)\n",
    "        # print(\"compute_loss(logits) :::: \", logits )\n",
    "        labels = inputs.get(\"labels\")\n",
    "\n",
    "        # 대조 손실 계산\n",
    "        # loss = contrastive_loss(embeddings, labels)\n",
    "        loss = multi_class_contrastive_loss(embeddings, labels) \n",
    "        # print(\"loss-ContrastiveTrainer : \", loss)\n",
    "        # loss_clamp = torch.clamp(loss, max=20)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "      # 모델의 출력을 얻기 위해 입력을 통과시킵니다.\n",
    "      outputs = model(**inputs)\n",
    "      \n",
    "      # 모델의 logits를 가져옵니다.\n",
    "      logits = outputs.logits\n",
    "      # print(\"compute_loss(logits) :::: \", outputs.logits )\n",
    "      # 레이블을 가져옵니다.\n",
    "      labels = inputs.get(\"labels\")\n",
    "\n",
    "      # CrossEntropyLoss를 사용하여 손실을 계산합니다.\n",
    "      loss_fct = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "      loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "      print(\"loss-customtrainer : \", loss)\n",
    "      return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPl6TZ7CGJ0p"
   },
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "XA9g2vV_GJ0p"
   },
   "outputs": [],
   "source": [
    "f1 = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # print(\"Predictions::\", predictions)  # 예측값 출력\n",
    "\n",
    "    # print(\"Predictions shape:\", prediction.shape)  # 예측값 출력\n",
    "    # print(\"Labels shape:\", labels.shape)            # 레이블 출력\n",
    "    # print(\"Predictions[0] : \", predictions[0])\n",
    "    print(\"Predictions[0][0] : \", predictions[0][0])\n",
    "    print(\"Predictions[0][1] : \", predictions[0][1])\n",
    "    print(\"type predictions[0][1] : \", type(predictions[0][1]))\n",
    "    print(\"len(predictions[1]) : \", len(predictions[1]))\n",
    "    # print(\"Predictions[1] : \", predictions[1])\n",
    "    predictions = np.argmax(predictions[0], axis=1)\n",
    "    print(\"Predictions argmax ::\", predictions)  # 예측값 출력\n",
    "    \n",
    "    print(\"Labels::\", labels)            # 레이블 출력\n",
    "    metrics = f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    print(\"Computed metrics:\", metrics)  # 계산된 메트릭 출력\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # print(\"Predictions::\", predictions)  # 예측값 출력\n",
    "    (1,)\n",
    "    [[]]\n",
    "    # print(\"Predictions shape:\", prediction.shape)  # 예측값 출력\n",
    "    # print(\"Labels shape:\", labels.shape)            # 레이블 출력\n",
    "    # print(\"Predictions[0] : \", predictions[0])\n",
    "    # print(\"Predictions[0][0] : \", predictions[0][0])\n",
    "    # print(\"Predictions[0][1] : \", predictions[0][1])\n",
    "    # print(\"type predictions[0][1] : \", type(predictions[0][1]))\n",
    "    # print(\"len(predictions[1]) : \", len(predictions[1]))\n",
    "    # print(\"Predictions[1] : \", predictions[1])\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # print(\"Predictions argmax ::\", predictions)  # 예측값 출력\n",
    "    print(\"Labels::\", labels)            # 레이블 출력\n",
    "    metrics = f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    print(\"Computed metrics:\", metrics)  # 계산된 메트릭 출력\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV2exsooGJ0p"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "OkQVpzabGJ0p"
   },
   "outputs": [],
   "source": [
    "### for wandb setting\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "SLV_Qq5bGJ0p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR +'/contrastive_ver1_step1',\n",
    "    logging_dir='./logs',  \n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    # report_to=\"wandb\",\n",
    "    logging_strategy='steps',\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    logging_steps=50,\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    learning_rate= 2e-05,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.999,\n",
    "    adam_epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='linear',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    greater_is_better=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "eGAepHgxGJ0p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = ContrastiveTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_valid,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "vJ_Vzpc9GJ0p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_loss(embeddings) :::: tensor([[ 0.1941, -0.3322, -0.0420,  ..., -0.1407, -0.0579,  0.2699],\n",
      "        [ 0.2096, -0.3080, -0.0259,  ..., -0.1491, -0.0122,  0.2819],\n",
      "        [ 0.2319, -0.3333, -0.0465,  ..., -0.1151, -0.1438,  0.2689],\n",
      "        ...,\n",
      "        [ 0.2519, -0.2791, -0.0172,  ..., -0.1796,  0.0138,  0.2855],\n",
      "        [ 0.2484, -0.2684, -0.0223,  ..., -0.1657,  0.0181,  0.2921],\n",
      "        [ 0.2539, -0.3408, -0.0402,  ..., -0.0893, -0.1582,  0.2762]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss_clamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/choihyunwoo_n/py_venv/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/choihyunwoo_n/py_venv/lib/python3.10/site-packages/transformers/trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2479\u001b[0m )\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/choihyunwoo_n/py_venv/lib/python3.10/site-packages/transformers/trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3585\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[226], line 21\u001b[0m, in \u001b[0;36mContrastiveTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m multi_class_contrastive_loss(embeddings, labels) \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(\"loss-ContrastiveTrainer : \", loss)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# loss_clamp = torch.clamp(loss, max=20)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss_clamp, outputs) \u001b[38;5;28;01mif\u001b[39;00m return_outputs \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mloss_clamp\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_clamp' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBXeP6ynGJ0p"
   },
   "source": [
    "## Re-labeling Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "eifEFgIOGJ0p"
   },
   "outputs": [],
   "source": [
    "origin_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "oO5h88_3GJ0q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ynat-v1_train_00000', 'ynat-v1_train_00001',\n",
       "       'ynat-v1_train_00002', ..., 'ynat-v1_train_02790',\n",
       "       'ynat-v1_train_02792', 'ynat-v1_train_02797'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = train_df['ID'].values\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2800/2800 [00:12<00:00, 227.35it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(OUTPUT_DIR+'/contrastive_ver1_step1' + \"/checkpoint-400\").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "new_train = origin_train.copy()\n",
    "\n",
    "for idx, sample in tqdm(origin_train.iterrows(), total=len(origin_train), desc=\"Evaluating\"):\n",
    "    target_id = sample['ID']\n",
    "    if target_id in ids :\n",
    "        cleaned_text = train_df.loc[train_df['ID'] == sample['ID']]['text'].values[0]\n",
    "        new_train.loc[new_train['ID'] == target_id, 'text'] = cleaned_text\n",
    "        continue\n",
    "\n",
    "    inputs = tokenizer(sample['text'], return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()\n",
    "        new_train.loc[new_train['ID'] == target_id, 'target'] = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(f'../data/self_train/contrastive_ver1_step1_multi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정파 미사일 이용기간 단 1분종 1보</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>찰스 국 회장 ^로한^ 송</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>北 김정은 자주통일 새 시대 열어 나가야 1보</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>미국 대선 앞두고 중국 단발이 비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                           text  target\n",
       "0  ynat-v1_train_00000           정파 미사일 이용기간 단 1분종 1보       4\n",
       "1  ynat-v1_train_00001                 찰스 국 회장 ^로한^ 송       3\n",
       "2  ynat-v1_train_00002     北 김정은 자주통일 새 시대 열어 나가야 1보        2\n",
       "3  ynat-v1_train_00003  갤노트8 주말 27만대 개통…시장은 불법 보조금 얼룩       1\n",
       "4  ynat-v1_train_00004      미국 대선 앞두고 중국 단발이 비해 감시 강화       6"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
