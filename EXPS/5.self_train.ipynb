{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ-n74gNGJ0n"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieJqZz6WGJ0n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import evaluate\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# wandb 프로젝트 설정\n",
    "os.environ[\"WANDB_PROJECT\"] = \"P3_relabeling\"\n",
    "# wandb 초기화\n",
    "wandb.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9MrGeVLGJ0o"
   },
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rojb26TRGJ0o"
   },
   "outputs": [],
   "source": [
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHiKw7tAGJ0o",
    "outputId": "fa675ab9-3221-4ef1-dabb-42e2aad2192c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ANUH4JCxGJ0o"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuP9IW9mGJ0o"
   },
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HH0lhDvhGJ0o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'klue/roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2NvoGbGJ0o"
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gE13nELlGJ0o"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(DATA_DIR, 'Self_train/self_train_step1.csv'))\n",
    "dataset_train, dataset_valid = train_test_split(data, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>ynat-v1_train_01040</td>\n",
       "      <td>2억 5천만 달러로 인프라 투자 확대</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>ynat-v1_train_01599</td>\n",
       "      <td>민주일반연맹 비정규직 차별철폐 공동행동</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ynat-v1_train_00194</td>\n",
       "      <td>서울자유시민대학 초대 학장에 정재권 전 한겨레신문 논설위원</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>ynat-v1_train_02461</td>\n",
       "      <td>아베 개헌논의 안 해도 좋은지 선거서 물을 것…개헌 이슈화</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>ynat-v1_train_01479</td>\n",
       "      <td>신간 \"우미령의 정복\" 연재 9기</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>ynat-v1_train_02543</td>\n",
       "      <td>박기원 감독 눈치 보지 말고…비예나 눈치 본 건 아닌데</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>ynat-v1_train_02090</td>\n",
       "      <td>삼성 갤럭시 J5가 동남아 시장에 출시</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>ynat-v1_train_02649</td>\n",
       "      <td>아이팩토리 상장폐지 이의신청서 제출</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>ynat-v1_train_00613</td>\n",
       "      <td>LG전자 미국서 G6 사면 구글 홈 증정</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>ynat-v1_train_01947</td>\n",
       "      <td>미래에셋대우 엔씨소프트 매출 1위 굳건…목표가↑</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                              text  target\n",
       "1040  ynat-v1_train_01040              2억 5천만 달러로 인프라 투자 확대       5\n",
       "1599  ynat-v1_train_01599             민주일반연맹 비정규직 차별철폐 공동행동       3\n",
       "194   ynat-v1_train_00194  서울자유시민대학 초대 학장에 정재권 전 한겨레신문 논설위원       3\n",
       "2461  ynat-v1_train_02461  아베 개헌논의 안 해도 좋은지 선거서 물을 것…개헌 이슈화       6\n",
       "1479  ynat-v1_train_01479                신간 \"우미령의 정복\" 연재 9기       0\n",
       "...                   ...                               ...     ...\n",
       "2543  ynat-v1_train_02543    박기원 감독 눈치 보지 말고…비예나 눈치 본 건 아닌데       1\n",
       "2090  ynat-v1_train_02090             삼성 갤럭시 J5가 동남아 시장에 출시       4\n",
       "2649  ynat-v1_train_02649               아이팩토리 상장폐지 이의신청서 제출       5\n",
       "613   ynat-v1_train_00613            LG전자 미국서 G6 사면 구글 홈 증정       4\n",
       "1947  ynat-v1_train_01947        미래에셋대우 엔씨소프트 매출 1위 굳건…목표가↑       5\n",
       "\n",
       "[2240 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>ynat-v1_train_02711</td>\n",
       "      <td>신동빈 경영복귀 첫 일성 적극적 투자로 국가 경제 이바지종합</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>ynat-v1_train_02156</td>\n",
       "      <td>나스닥 c6M폭락!6개월만에I최C폭 하락종합</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ynat-v1_train_00549</td>\n",
       "      <td>中공안 장쑤 화학공단 폭발참사 책임자들 구금</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>ynat-v1_train_00933</td>\n",
       "      <td>더위 식히는 장맛비…남부·제주도 밤에 대부분 그쳐</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>ynat-v1_train_00186</td>\n",
       "      <td>KB증권 농심 4분기 라면 부문 실적개선…목표주가↑</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>ynat-v1_train_00873</td>\n",
       "      <td>대한항공 63편 항공기가 9시간 지연됨</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>ynat-v1_train_01144</td>\n",
       "      <td>N 비료 생산업체, 권마다 복제되는 논 위키백과 책 2 없나요?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>ynat-v1_train_01775</td>\n",
       "      <td>시즌 첫 골 손흥민 모든 상황 준비해 좋은 결과로 이어졌다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>ynat-v1_train_00394</td>\n",
       "      <td>8시 30분 시리얼 순찰 후</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>ynat-v1_train_01123</td>\n",
       "      <td>무릎 부상 즐라탄 시즌 아웃…내년 1월까지 출전 못해</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                 text  target\n",
       "2711  ynat-v1_train_02711    신동빈 경영복귀 첫 일성 적극적 투자로 국가 경제 이바지종합       3\n",
       "2156  ynat-v1_train_02156             나스닥 c6M폭락!6개월만에I최C폭 하락종합       5\n",
       "549   ynat-v1_train_00549             中공안 장쑤 화학공단 폭발참사 책임자들 구금       6\n",
       "933   ynat-v1_train_00933          더위 식히는 장맛비…남부·제주도 밤에 대부분 그쳐       0\n",
       "186   ynat-v1_train_00186         KB증권 농심 4분기 라면 부문 실적개선…목표주가↑       5\n",
       "...                   ...                                  ...     ...\n",
       "873   ynat-v1_train_00873                대한항공 63편 항공기가 9시간 지연됨       0\n",
       "1144  ynat-v1_train_01144  N 비료 생산업체, 권마다 복제되는 논 위키백과 책 2 없나요?       3\n",
       "1775  ynat-v1_train_01775     시즌 첫 골 손흥민 모든 상황 준비해 좋은 결과로 이어졌다       1\n",
       "394   ynat-v1_train_00394                      8시 30분 시리얼 순찰 후       6\n",
       "1123  ynat-v1_train_01123        무릎 부상 즐라탄 시즌 아웃…내년 1월까지 출전 못해       1\n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9BQVS286GJ0o"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        input_texts = data['text']\n",
    "        targets = data['target']\n",
    "        self.inputs = []; self.labels = []\n",
    "        for text, label in zip(input_texts, targets):\n",
    "            tokenized_input = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', return_token_type_ids=False)\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'].squeeze(0),\n",
    "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx].squeeze(0)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BVycj2wPGJ0p"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, tokenizer)\n",
    "data_valid = BERTDataset(dataset_valid, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5yh5dYa0GJ0p"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPl6TZ7CGJ0p"
   },
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XA9g2vV_GJ0p"
   },
   "outputs": [],
   "source": [
    "f1 = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return f1.compute(predictions=predictions, references=labels, average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV2exsooGJ0p"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OkQVpzabGJ0p"
   },
   "outputs": [],
   "source": [
    "### for wandb setting\n",
    "#os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SLV_Qq5bGJ0p"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR+\"/self_train_step1\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    report_to=\"wandb\",\n",
    "    logging_strategy='steps',\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    learning_rate= 2e-05,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.999,\n",
    "    adam_epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='linear',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    greater_is_better=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "eGAepHgxGJ0p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_valid,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vJ_Vzpc9GJ0p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkangjeonhwi\u001b[0m (\u001b[33mkangjeonhwi1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/kjh/wandb/run-20241103_185820-fde8hzti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kangjeonhwi1/P3_self_training/runs/fde8hzti' target=\"_blank\">/data/ephemeral/home/kjh/outputs/self_train_step1</a></strong> to <a href='https://wandb.ai/kangjeonhwi1/P3_self_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kangjeonhwi1/P3_self_training' target=\"_blank\">https://wandb.ai/kangjeonhwi1/P3_self_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kangjeonhwi1/P3_self_training/runs/fde8hzti' target=\"_blank\">https://wandb.ai/kangjeonhwi1/P3_self_training/runs/fde8hzti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 19:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.931601</td>\n",
       "      <td>0.724267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.328600</td>\n",
       "      <td>0.908999</td>\n",
       "      <td>0.740844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.328600</td>\n",
       "      <td>0.880327</td>\n",
       "      <td>0.741697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.194600</td>\n",
       "      <td>1.016557</td>\n",
       "      <td>0.709236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.194600</td>\n",
       "      <td>1.006281</td>\n",
       "      <td>0.725404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.170100</td>\n",
       "      <td>0.991075</td>\n",
       "      <td>0.741623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.170100</td>\n",
       "      <td>1.000813</td>\n",
       "      <td>0.742937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=2.318537434169224, metrics={'train_runtime': 1193.2862, 'train_samples_per_second': 9.386, 'train_steps_per_second': 0.293, 'total_flos': 1.04378076020736e+16, 'train_loss': 2.318537434169224, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_path = os.path.join(DATA_DIR, \"cleaning_step1\")\n",
    "\n",
    "noise_list = []\n",
    "for label in range(7) :\n",
    "    df = pd.read_csv(labeled_data_path+f\"/c1_label_dropped_{label}.csv\")\n",
    "    noise_list.append(df)\n",
    "\n",
    "noise_df = pd.concat(noise_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ynat-v1_train_00015', 'ynat-v1_train_00066',\n",
       "       'ynat-v1_train_00079', ..., 'ynat-v1_train_02742',\n",
       "       'ynat-v1_train_02764', 'ynat-v1_train_02787'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = noise_df['ID'].values\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2800/2800 [00:39<00:00, 70.67it/s] \n"
     ]
    }
   ],
   "source": [
    "origin_train = pd.read_csv(os.path.join(DATA_DIR, 'Self_train/self_train_step1.csv'))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(OUTPUT_DIR+\"/self_train_step1/checkpoint-350\").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "new_train = origin_train.copy()\n",
    "\n",
    "for idx, sample in tqdm(origin_train.iterrows(), total=len(origin_train), desc=\"Evaluating\"):\n",
    "    target_id = sample['ID']\n",
    "\n",
    "    if target_id in ids :\n",
    "        continue\n",
    "\n",
    "    inputs = tokenizer(sample['text'], return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()\n",
    "        new_train.loc[new_train['ID'] == target_id, 'target'] = pred[0]\n",
    "\n",
    "new_train.to_csv(f'./data/Self_train/self_train_step2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBXeP6ynGJ0p"
   },
   "source": [
    "## Evaluate Model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
